= Lab 04 technical notes

== Spring 2017

big issues with espina.

Last fall created a new approach but did not document fully.

Lab 04 now has a multiple manos/one Jenkins topology (which worked pretty well last fall).

Key: everyone is logged in as public1 (any public ID, actually - key is that they are all the same) and the VMs are all forced into the same network. This solves many problems, at the disadvantage of an artificial environment with everyone logged in as the same ID.

The key is to have one master pipeline, call it Calavera00, that people can attach their individual manosXX servers to.

* `su public1 && cd ~`
* `vagrant plugin install vagrant-berkshelf`
* `git clone https://github.com/dm-academy/Calavera.git`
* `./template.sh 1`
* ``./startup.sh`   # not sudo
* `vagrant up cerebro1 brazos1 espina1 hombros1 manos1 cara1`

== Spring 2016 notes
Was not able to start a public5 pipeline due to Tomcat recipe being upgraded and a fresh Berkshelf cache for public5. Public1-4 have cached v0.17 which defaults to Tomcat 6, but new Berks gives 0.2 which defaults to NO tomcat - you have to specify.

== Overview
This lab relies on the new templated Vagrant file. You need to:

* Create four users, public1-4, with directories /home/publicx
* su to each in turn
* Clone Calavera to ~
* Run ./template.sh, passing an argument 1-4 to it corresponding to the current user
* vagrant up the corresponding machines, now named cerebro1-4, brazos1-4, etc.
* copy the Calavera/shared/keys directory from some other working instance or run startup.sh. (error - they won't have rights to copy vm to /var/vagrant/boxes)

A 48 gb server can run 4 pipelines of 6 machines each.

Each of the 4 users may need to re-install berkshelf:

$ vagrant plugin install vagrant-berkshelf

The order of machines is:

vagrant up cerebro
vagrant up brazos
vagrant up espina
vagrant up hombros
vagrant up manos
vagrant up cara

== Previous notes

Crafting a Vagrant-based end to end DevOps pipeline that can support an entire class turned out to be a nontrivial undertaking, with some initially attempted approaches crashing and burning badly.

Vagrant has certain restrictions, and in particular restricts ssh access to VMs to the user under which they were created. If there are workarounds, I have not been able to find them - suggestions appreciated. So, this lab represents certain compromises.

The options considered were:

. each team has full control over own local pipeline (e.g. running on that person's laptop or course workstation)
. each team has full control over a distinct pipeline on the server (each team has own instance of 6 vms, for a total of e.g. 24 for a 4-team class, quite a load on the server)
.. the other issue with this was encountered Spring 2015 when machines from the various pipelines would disappear, probably due to Vagrant/Virtualbox networking issues
.. this is the preferred mode for Section II however and when the pipeline is switched to Docker we will revisit.
. one shared pipeline, with different apps having different URLs, but distinct dev instances run on their local laptops
. one shared pipeline, distinct dev instances on server
. one shared pipline, one dev server with separate apps
.. distinct Tomcat instances
.. distinct URLs

Option 2 was finally determined workable.

Considering final option:

In order to do this with Vagrant (and this is the major compromise) it is necessary for all students to access the Vagrant VMs as a single user, e.g. "public." Each student does `su public`, cds to /home/public/calavera, and then `ssh manos` (or whatever Calavera server they choose).

There is risk here; students would have the permissions to modify and destroy Calavera servers running under public, but we just have to manage this. Fortunately, any server can be easily rebuilt.

= Thinking about one pipeline, multiple products
(ultimately this was not the chosen route)
In order to do this, some brute force configuration is required including the creation of multiple dev directories and Tomcat URL mappings. (Alternative: four production servers. Four build servers, configured on the fly.)

"Hijo" will remain the default primary product. For Lab 04 (as being implemented for 4 teams) we will add:

* gatito (kitten)
* perrito (puppy)
* potro (foal)
* cabrito (kid, i.e. baby goat)

This means that we need to handle 5 distinct

* development trees in /home
* build scripts
* Tomcat servlets
* githooks
* Jenkins jobs
* Artifactory packages
* Cara deployments

Here is the core idea for the lab: each team analyzes the reference model that Hijo provides, and replicates it. Worth a try...

Trouble is, we wind up with a shared web.xml file for Tomcat. No good, for Section II, as each team is supposed to be independent. so, this resource will need to be restricted to overall Manos configuration and removed from the local team builds.

Each student, or subteam of 2 within the larger team, would have their own instance:

/home/gatito01 and /home/gatito02, both cloned from /home/gatito on Cerebro - this way they can do true collab dev.

In considering the complexity of retrofitting the entire pipeline with 5 sub-pipelines... this is too much work and complexity. Going to re-visit standing up 4 distinct pipelines on the server, trying different internet & username approaches.


== Helpful links

* http://www.cyberciti.biz/cloud-computing/use-vagrant-to-create-small-virtual-lab-on-linux-osx/[How To Use Vagrant To Create Small Virtual Test Lab on a Linux / OS X / MS-Windows]
